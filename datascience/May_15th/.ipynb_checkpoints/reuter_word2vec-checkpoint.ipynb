{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia2014 + Gigaword5 and GloVe\n",
    "ref: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.Session(config = config)\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, LSTM, Flatten, Dense, Dropout, Reshape, Bidirectional, Conv2D, MaxPool2D, Concatenate, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "VALIDATION_SPLIT = 0.3\n",
    "#############################################################################\n",
    "# TODO: this should be the same as the dimension of word embedding you are  #\n",
    "# using                                                                     #\n",
    "#############################################################################\n",
    "EMBEDDING_DIM = 50\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: please assign the absolute path to the GloVe txt file               #\n",
    "# (glove.6B.50d.txt or any dimension you like)                              #\n",
    "#############################################################################\n",
    "path_to_glove = '/home/robinlin/Desktop/secsemesInJunior/datascience/May_15th/glove.6B/glove.6B.50d.txt'\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "tmp_file_name = 'word2vec.6B.txt'\n",
    "\n",
    "glove_file = datapath(path_to_glove)\n",
    "tmp_file = get_tmpfile(tmp_file_name)\n",
    "\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the type the word vector of 'animal', the dimension (shape) of this vector, and the content of thie vector.\n",
    "\n",
    "If you use 300 dimensions word vectors, the correct outout will be something like this:\n",
    "```\n",
    "(numpy.ndarray,\n",
    " (300,),\n",
    " array([ 0.25653  ,  0.66592  , -0.5313   ,  0.20342  ,  0.40049  ,\n",
    " ... multiple lines are omitted ...\n",
    "        -0.14921  ,  0.2404   ,  0.22182  ,  0.68883  , -0.018991 ],\n",
    "       dtype=float32))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[ 0.49652   -0.65143   -1.0869    -0.10205    0.81724    0.923\n",
      " -0.56206   -1.3801     1.8115     0.068438   0.63906    0.24468\n",
      "  1.0308     0.10202    0.48498   -0.08387    0.61688    0.35812\n",
      " -0.75196   -0.3548    -0.14173    0.042311   0.42242   -0.21013\n",
      "  0.28935   -1.1214    -0.5278    -0.046298   0.064643  -0.43924\n",
      "  2.4004    -0.29715   -0.19765   -0.88725   -0.62955    0.64092\n",
      "  0.14741   -0.0089431  0.39569    0.060899  -0.33917   -0.15897\n",
      "  0.22115    0.83813    1.6032    -0.010252  -0.36843   -0.32005\n",
      "  0.4658    -0.10813  ]\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: please print the type the word vector of 'animal', the dimension    #\n",
    "# (shape) of this vector, and the content of thie vector.                   #\n",
    "#############################################################################\n",
    "print(type(model.get_vector('animal')))\n",
    "print(model.get_vector('animal'))\n",
    "print(model.get_vector('animal').shape)\n",
    "\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [similar_by_vector](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.similar_by_vector) to obtain the 10 most similar word to 'france'\n",
    "\n",
    "If you use 300 dimensions word vectors, the correct outout will be something like this:\n",
    "```\n",
    "[('france', 1.0),\n",
    " ('french', 0.7344760894775391),\n",
    " ('paris', 0.6580672264099121),\n",
    " ('belgium', 0.620672345161438),\n",
    " ('spain', 0.573593258857727),\n",
    " ('italy', 0.5643459558486938),\n",
    " ('germany', 0.5567397475242615),\n",
    " ('prohertrib', 0.5564222931861877),\n",
    " ('britain', 0.5553334951400757),\n",
    " ('chirac', 0.5362644195556641)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', 0.9999999403953552),\n",
       " ('french', 0.8868120908737183),\n",
       " ('belgium', 0.8631513118743896),\n",
       " ('paris', 0.8025329113006592),\n",
       " ('spain', 0.7909148931503296),\n",
       " ('netherlands', 0.7893801331520081),\n",
       " ('italy', 0.7788637280464172),\n",
       " ('germany', 0.7744609117507935),\n",
       " ('european', 0.7626757025718689),\n",
       " ('switzerland', 0.757765531539917)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: use similar_by_vector to obtain the 10 most similar word to 'france'#\n",
    "#############################################################################\n",
    "model.similar_by_vector(model.get_vector('france'))\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [most_similar](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.Word2VecKeyedVectors.most_similar) to obtain the result of 'woman' + 'king' - 'man'\n",
    "\n",
    "If you use 300 dimensions, the correct output will be somthing like this:\n",
    "```\n",
    "[('queen', 0.6713277101516724),\n",
    " ('princess', 0.5432624220848083),\n",
    " ('throne', 0.5386104583740234),\n",
    " ('monarch', 0.5347574949264526),\n",
    " ('daughter', 0.498025119304657),\n",
    " ('mother', 0.4956442713737488),\n",
    " ('elizabeth', 0.4832652509212494),\n",
    " ('kingdom', 0.47747087478637695),\n",
    " ('prince', 0.4668239951133728),\n",
    " ('wife', 0.4647327661514282)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523603677749634),\n",
       " ('throne', 0.7664334177970886),\n",
       " ('prince', 0.759214460849762),\n",
       " ('daughter', 0.7473883032798767),\n",
       " ('elizabeth', 0.7460220456123352),\n",
       " ('princess', 0.7424569725990295),\n",
       " ('kingdom', 0.7337411642074585),\n",
       " ('monarch', 0.7214490175247192),\n",
       " ('eldest', 0.7184861898422241),\n",
       " ('widow', 0.7099430561065674)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: use most_similar to obtain the result of 'woman' + 'king' - 'man'   #\n",
    "#############################################################################\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [doesnt_match](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.doesnt_match) to obtain the word with the different meaning with the other words in a list 'breakfast', 'lunch', 'dinner', 'cereal'\n",
    "\n",
    "If you use 300 dimensions, the correct output will be something like this:\n",
    "```\n",
    "'cereal'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: Use doesnt_match to obtain the word with the different meaning with #\n",
    "# the other words in a list 'breakfast', 'lunch', 'dinner', 'cereal'        #\n",
    "#############################################################################\n",
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pca_plot(model):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = PCA(n_components = 2)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    for i in range(len(x)):\n",
    "        label = labels[i]\n",
    "        if label in ['king', 'queen', 'sister', 'brother', 'niece', 'nephew', 'aunt', 'uncle', 'woman', 'man', \n",
    "                     'madam', 'sir']:\n",
    "            plt.scatter(x[i],y[i])\n",
    "            plt.annotate(label,\n",
    "                         xy = (x[i], y[i]),\n",
    "                         xytext = (5, 2),\n",
    "                         textcoords = 'offset points',\n",
    "                         ha = 'right',\n",
    "                         va = 'bottom')\n",
    "    plt.show()\n",
    "\n",
    "pca_plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuter-21578 Data set with word2vec\n",
    "Last week, you have already worked on Reuters-21578 dataset for multi-class classification. This week, you are using word2vec to classify the same dataset.\n",
    "\n",
    "In this lab, you will have to implement 3 three neural network models using keras API:\n",
    "1. Mutilayer perceptron\n",
    "2. Conv1D\n",
    "3. LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n"
     ]
    }
   ],
   "source": [
    "# this requires download from the first time\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = MAX_NB_WORDS, \n",
    "                                                         skip_top = 0, \n",
    "                                                         maxlen = MAX_SEQUENCE_LENGTH,\n",
    "                                                         seed = 113,\n",
    "                                                         start_char = 1, \n",
    "                                                         oov_char = 2, \n",
    "                                                         index_from = 3)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "word2index = reuters.get_word_index()\n",
    "word2index = {key : (value + 3) for (key, value) in word2index.items()}\n",
    "word2index['<PAD>'] = 0\n",
    "word2index['<START>'] = 1\n",
    "word2index['<UNK>'] = 2\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: create a embeddings_index to map word to word vector and print the  #\n",
    "# number of words in the embedding                                          #\n",
    "#############################################################################\n",
    "embeddings_index = dict()\n",
    "for (key, value) in word2index.items():\n",
    "    \n",
    "    try: \n",
    "        embeddings_index[key] = model.get_vector(key)\n",
    "    except: \n",
    "        embeddings_index[key] = np.zeros((EMBEDDING_DIM,))\n",
    "#         print('{} not in wordvectors'.format(key))\n",
    "\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# TODO: create a embedding_matrix that map the index of word2index to word  #\n",
    "# vectors                                                                   #\n",
    "#############################################################################\n",
    "embedding_matrix = np.zeros((MAX_NB_WORDS, EMBEDDING_DIM))\n",
    "\n",
    "for (key, value) in word2index.items():\n",
    "    if (value < MAX_NB_WORDS):\n",
    "        embedding_matrix[value] = embeddings_index[key]\n",
    "    else:\n",
    "        continue\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# TODO: define an embedding layer that initialize the weights with          #                                         \n",
    "# embedding_matrix and set trainable to False                               #\n",
    "#############################################################################\n",
    "pass\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "embedding_layer = Embedding(MAX_NB_WORDS,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SEQUENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Use keras pad_sequences to pad the sequence in X_train and X_test   #\n",
    "# to MAX_SEQUENCE_LENGTH                                                    #\n",
    "#############################################################################\n",
    "# print(X_train[0])\n",
    "# print(X_test[0])\n",
    "# X_train_shape = X_train.shape\n",
    "# X_test_shape = X_test.shape\n",
    "# print(X_train_shape)\n",
    "# print(X_test_shape)\n",
    "# X_train2 = np.zeros((len(X_train)))\n",
    "X_train = pad_sequences(X_train, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train tensor: (7976, 300)\n",
      "Shape of X_test tensor: (1994, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train tensor:', X_train.shape)\n",
    "print('Shape of X_test tensor:', X_test.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_train = X_train[indices]\n",
    "y_train = y_train[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * X_train.shape[0])\n",
    "\n",
    "X_val = X_train[-nb_validation_samples:]\n",
    "y_val = y_train[-nb_validation_samples:]\n",
    "X_train = X_train[:-nb_validation_samples]\n",
    "y_train = y_train[:-nb_validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + multiple layer perceptron\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 300)               0         \n",
    "_________________________________________________________________\n",
    "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 90000)             0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 128)               11520128  \n",
    "_________________________________________________________________\n",
    "activation_1 (Activation)    (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 64)                8256      \n",
    "_________________________________________________________________\n",
    "activation_2 (Activation)    (None, 64)                0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 32)                2080      \n",
    "_________________________________________________________________\n",
    "activation_3 (Activation)    (None, 32)                0         \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 46)                1518      \n",
    "_________________________________________________________________\n",
    "activation_4 (Activation)    (None, 46)                0         \n",
    "=================================================================\n",
    "Total params: 20,826,882\n",
    "Trainable params: 11,531,982\n",
    "Non-trainable params: 9,294,900\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 300, 50)           500000    \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 15000)             0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 128)               1920128   \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 46)                1518      \n",
      "=================================================================\n",
      "Total params: 2,431,982\n",
      "Trainable params: 1,931,982\n",
      "Non-trainable params: 500,000\n",
      "_________________________________________________________________\n",
      "Train on 5584 samples, validate on 2392 samples\n",
      "Epoch 1/20\n",
      "5584/5584 [==============================] - 3s 471us/step - loss: 3.8222 - acc: 0.2842 - val_loss: 3.8142 - val_acc: 0.2170\n",
      "Epoch 2/20\n",
      "5584/5584 [==============================] - 2s 328us/step - loss: 3.8082 - acc: 0.2772 - val_loss: 3.7998 - val_acc: 0.2170\n",
      "Epoch 3/20\n",
      "5584/5584 [==============================] - 2s 329us/step - loss: 3.7941 - acc: 0.2249 - val_loss: 3.7856 - val_acc: 0.2170\n",
      "Epoch 4/20\n",
      "5584/5584 [==============================] - 2s 329us/step - loss: 3.7802 - acc: 0.2249 - val_loss: 3.7714 - val_acc: 0.2170\n",
      "Epoch 5/20\n",
      "5584/5584 [==============================] - 2s 332us/step - loss: 3.7663 - acc: 0.3453 - val_loss: 3.7573 - val_acc: 0.3980\n",
      "Epoch 6/20\n",
      "5584/5584 [==============================] - 2s 331us/step - loss: 3.7525 - acc: 0.3748 - val_loss: 3.7433 - val_acc: 0.3980\n",
      "Epoch 7/20\n",
      "5584/5584 [==============================] - 2s 417us/step - loss: 3.7388 - acc: 0.3748 - val_loss: 3.7294 - val_acc: 0.3980\n",
      "Epoch 8/20\n",
      "5584/5584 [==============================] - 2s 351us/step - loss: 3.7252 - acc: 0.3748 - val_loss: 3.7156 - val_acc: 0.3980\n",
      "Epoch 9/20\n",
      "5584/5584 [==============================] - 2s 335us/step - loss: 3.7117 - acc: 0.3748 - val_loss: 3.7018 - val_acc: 0.3980\n",
      "Epoch 10/20\n",
      "5584/5584 [==============================] - 2s 335us/step - loss: 3.6983 - acc: 0.3748 - val_loss: 3.6881 - val_acc: 0.3980\n",
      "Epoch 11/20\n",
      "5584/5584 [==============================] - 2s 334us/step - loss: 3.6849 - acc: 0.3748 - val_loss: 3.6746 - val_acc: 0.3980\n",
      "Epoch 12/20\n",
      "5584/5584 [==============================] - 2s 333us/step - loss: 3.6716 - acc: 0.3748 - val_loss: 3.6612 - val_acc: 0.3980\n",
      "Epoch 13/20\n",
      "5584/5584 [==============================] - 2s 330us/step - loss: 3.6585 - acc: 0.3748 - val_loss: 3.6477 - val_acc: 0.3980\n",
      "Epoch 14/20\n",
      "5584/5584 [==============================] - 2s 331us/step - loss: 3.6454 - acc: 0.3748 - val_loss: 3.6345 - val_acc: 0.3980\n",
      "Epoch 15/20\n",
      "5584/5584 [==============================] - 2s 336us/step - loss: 3.6324 - acc: 0.3748 - val_loss: 3.6212 - val_acc: 0.3980\n",
      "Epoch 16/20\n",
      "5584/5584 [==============================] - 2s 339us/step - loss: 3.6195 - acc: 0.3748 - val_loss: 3.6081 - val_acc: 0.3980\n",
      "Epoch 17/20\n",
      "5584/5584 [==============================] - 2s 346us/step - loss: 3.6066 - acc: 0.3748 - val_loss: 3.5951 - val_acc: 0.3980\n",
      "Epoch 18/20\n",
      "5584/5584 [==============================] - 3s 469us/step - loss: 3.5939 - acc: 0.3748 - val_loss: 3.5821 - val_acc: 0.3980\n",
      "Epoch 19/20\n",
      "5584/5584 [==============================] - 2s 335us/step - loss: 3.5812 - acc: 0.3748 - val_loss: 3.5693 - val_acc: 0.3980\n",
      "Epoch 20/20\n",
      "5584/5584 [==============================] - 2s 381us/step - loss: 3.5686 - acc: 0.3748 - val_loss: 3.5565 - val_acc: 0.3980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f7a8c6c88>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: Define the model of multiple layer perceptron similar to the model  #\n",
    "# summary above into the variable model, compile it and fit it.             #\n",
    "#############################################################################\n",
    "#from keras.models import Sequential\n",
    "\n",
    "\n",
    "input_layer = Input(shape = (MAX_SEQUENCE_LENGTH, ))\n",
    "embedding = embedding_layer(input_layer)\n",
    "flatten = Flatten()(embedding)\n",
    "dense1 = Dense(128, activation = 'relu')(flatten)\n",
    "dense2 = Dense(64, activation = 'relu')(dense1)\n",
    "dense3 = Dense(32, activation = 'relu')(dense2)\n",
    "dense4 = Dense(46, activation = 'softmax')(dense3)\n",
    "\n",
    "model = Model(inputs = input_layer, outputs = dense4)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          epochs = 20, \n",
    "          batch_size = 512, \n",
    "          validation_data = (X_val, y_val))\n",
    "\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994/1994 [==============================] - 0s 248us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.564562201141235, 0.3966900703301999]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + Conv1D\n",
    "```\n",
    "_________________________________________________________________\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_2 (InputLayer)         (None, 300)               0         \n",
    "_________________________________________________________________\n",
    "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
    "_________________________________________________________________\n",
    "conv1d_1 (Conv1D)            (None, 296, 64)           96064     \n",
    "_________________________________________________________________\n",
    "max_pooling1d_1 (MaxPooling1 (None, 59, 64)            0         \n",
    "_________________________________________________________________\n",
    "flatten_2 (Flatten)          (None, 3776)              0         \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 3776)              0         \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 64)                241728    \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 64)                0         \n",
    "_________________________________________________________________\n",
    "dense_6 (Dense)              (None, 46)                2990      \n",
    "=================================================================\n",
    "Total params: 9,635,682\n",
    "Trainable params: 340,782\n",
    "Non-trainable params: 9,294,900\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 300, 50)           1549150   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 15000)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               1920128   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 46)                1518      \n",
      "=================================================================\n",
      "Total params: 3,481,132\n",
      "Trainable params: 1,931,982\n",
      "Non-trainable params: 1,549,150\n",
      "_________________________________________________________________\n",
      "Train on 5584 samples, validate on 2392 samples\n",
      "Epoch 1/20\n",
      "5584/5584 [==============================] - 2s 370us/step - loss: 1.0614 - acc: 0.7434 - val_loss: 1.9873 - val_acc: 0.5723\n",
      "Epoch 2/20\n",
      "5584/5584 [==============================] - 2s 408us/step - loss: 0.6730 - acc: 0.8286 - val_loss: 2.0171 - val_acc: 0.5602\n",
      "Epoch 3/20\n",
      "5584/5584 [==============================] - 2s 330us/step - loss: 0.5718 - acc: 0.8596 - val_loss: 2.0004 - val_acc: 0.5681\n",
      "Epoch 4/20\n",
      "5584/5584 [==============================] - 2s 333us/step - loss: 0.5170 - acc: 0.8789 - val_loss: 1.9720 - val_acc: 0.5803\n",
      "Epoch 5/20\n",
      "5584/5584 [==============================] - 2s 333us/step - loss: 0.4714 - acc: 0.8899 - val_loss: 1.9796 - val_acc: 0.5832\n",
      "Epoch 6/20\n",
      "5584/5584 [==============================] - 2s 337us/step - loss: 0.4358 - acc: 0.8974 - val_loss: 1.9846 - val_acc: 0.5916\n",
      "Epoch 7/20\n",
      "5584/5584 [==============================] - 2s 333us/step - loss: 0.4091 - acc: 0.9028 - val_loss: 2.0089 - val_acc: 0.5874\n",
      "Epoch 8/20\n",
      "5584/5584 [==============================] - 2s 374us/step - loss: 0.3830 - acc: 0.9112 - val_loss: 2.0603 - val_acc: 0.5903\n",
      "Epoch 9/20\n",
      "5584/5584 [==============================] - 4s 655us/step - loss: 0.3584 - acc: 0.9148 - val_loss: 2.0725 - val_acc: 0.5849\n",
      "Epoch 10/20\n",
      "5584/5584 [==============================] - 3s 534us/step - loss: 0.3316 - acc: 0.9232 - val_loss: 2.0942 - val_acc: 0.5966\n",
      "Epoch 11/20\n",
      "5584/5584 [==============================] - 2s 393us/step - loss: 0.3084 - acc: 0.9284 - val_loss: 2.1296 - val_acc: 0.5890\n",
      "Epoch 12/20\n",
      "5584/5584 [==============================] - 2s 329us/step - loss: 0.2875 - acc: 0.9316 - val_loss: 2.1553 - val_acc: 0.5895\n",
      "Epoch 13/20\n",
      "5584/5584 [==============================] - 2s 324us/step - loss: 0.2679 - acc: 0.9359 - val_loss: 2.1797 - val_acc: 0.5865\n",
      "Epoch 14/20\n",
      "5584/5584 [==============================] - 2s 324us/step - loss: 0.2474 - acc: 0.9422 - val_loss: 2.2225 - val_acc: 0.5936\n",
      "Epoch 15/20\n",
      "5584/5584 [==============================] - 2s 324us/step - loss: 0.2333 - acc: 0.9459 - val_loss: 2.2523 - val_acc: 0.5920\n",
      "Epoch 16/20\n",
      "5584/5584 [==============================] - 2s 340us/step - loss: 0.2117 - acc: 0.9513 - val_loss: 2.2768 - val_acc: 0.5928\n",
      "Epoch 17/20\n",
      "5584/5584 [==============================] - 2s 352us/step - loss: 0.2008 - acc: 0.9538 - val_loss: 2.3275 - val_acc: 0.5857\n",
      "Epoch 18/20\n",
      "5584/5584 [==============================] - 2s 344us/step - loss: 0.1888 - acc: 0.9561 - val_loss: 2.3253 - val_acc: 0.5870\n",
      "Epoch 19/20\n",
      "5584/5584 [==============================] - 2s 353us/step - loss: 0.1733 - acc: 0.9565 - val_loss: 2.3589 - val_acc: 0.5890\n",
      "Epoch 20/20\n",
      "5584/5584 [==============================] - 2s 342us/step - loss: 0.1625 - acc: 0.9622 - val_loss: 2.3935 - val_acc: 0.5844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f72ff49b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: Define the model of 1D convolution similar to the model summary     #\n",
    "# above into the variable model, compile it and fit it.                     #\n",
    "#############################################################################\n",
    "\n",
    "# input_layer = Input(shape = (MAX_SEQUENCE_LENGTH, ))\n",
    "# embedding = embedding_layer(input_layer)\n",
    "# flatten = Flatten()(embedding)\n",
    "# dense1 = Dense(128, activation = 'relu')(flatten)\n",
    "# dense2 = Dense(64, activation = 'relu')(dense1)\n",
    "# dense3 = Dense(32, activation = 'relu')(dense2)\n",
    "# dense4 = Dense(46, activation = 'softmax')(dense3)\n",
    "\n",
    "\n",
    "input_2 = Input(shape = (MAX_SEQUENCE_LENGTH,))\n",
    "embedding_1 = embedding_layer(input_2)\n",
    "conv1d_1 = Conv1D(64, 4)(embedding_1)\n",
    "max_pooling1d_1 = MaxPooling1D(5)(conv1d_1)\n",
    "flatten_2 = Flatten()(max_pooling1d_1)\n",
    "dropout_1 = Dropout(0.4)(flatten_2)\n",
    "dense_5 = Dense(64, activation = 'relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.3)(dense_5)\n",
    "dense_6 = Dense(46, activation = 'softmax')(dropout_2)\n",
    "\n",
    "\n",
    "\n",
    "print( len(word2index))\n",
    "# input_2 (InputLayer)         (None, 300)               0         \n",
    "# _________________________________________________________________\n",
    "# embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
    "# _________________________________________________________________\n",
    "# conv1d_1 (Conv1D)            (None, 296, 64)           96064     \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_1 (MaxPooling1 (None, 59, 64)            0         \n",
    "# _________________________________________________________________\n",
    "# flatten_2 (Flatten)          (None, 3776)              0         \n",
    "# _________________________________________________________________\n",
    "# dropout_1 (Dropout)          (None, 3776)              0         \n",
    "# _________________________________________________________________\n",
    "# dense_5 (Dense)              (None, 64)                241728    \n",
    "# _________________________________________________________________\n",
    "# dropout_2 (Dropout)          (None, 64)                0         \n",
    "# _________________________________________________________________\n",
    "# dense_6 (Dense)              (None, 46)                2990      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs = input_layer, outputs = dense4)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          epochs = 20, \n",
    "          batch_size = 512, \n",
    "          validation_data = (X_val, y_val))\n",
    "\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + LSTM (GRU)\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_3 (InputLayer)         (None, 300)               0         \n",
    "_________________________________________________________________\n",
    "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
    "_________________________________________________________________\n",
    "lstm_1 (LSTM)                (None, 128)               219648    \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 46)                5934      \n",
    "=================================================================\n",
    "Total params: 9,520,482\n",
    "Trainable params: 225,582\n",
    "Non-trainable params: 9,294,900\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = 'int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "units = 128\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "layer1 = LSTM(units,\n",
    "    dropout = 0.2,\n",
    "    recurrent_dropout = 0.2,\n",
    "    return_sequences = False)\n",
    "x = layer1(embedded_sequences)\n",
    "\n",
    "final_layer = Dense(46, activation = 'softmax')\n",
    "preds = final_layer(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "print(model.summary())\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data = (X_val, y_val),\n",
    "          epochs = 20, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
