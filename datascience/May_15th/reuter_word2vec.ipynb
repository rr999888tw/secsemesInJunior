{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia2014 + Gigaword5 and GloVe\n",
    "ref: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.Session(config = config)\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, LSTM, Flatten, Dense, Dropout, Reshape, Bidirectional, Conv2D, MaxPool2D, Concatenate, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "VALIDATION_SPLIT = 0.3\n",
    "#############################################################################\n",
    "# TODO: this should be the same as the dimension of word embedding you are  #\n",
    "# using                                                                     #\n",
    "#############################################################################\n",
    "EMBEDDING_DIM = 50\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: please assign the absolute path to the GloVe txt file               #\n",
    "# (glove.6B.50d.txt or any dimension you like)                              #\n",
    "#############################################################################\n",
    "path_to_glove = '/home/robinlin/Desktop/secsemesInJunior/datascience/May_15th/glove.6B/glove.6B.50d.txt'\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "tmp_file_name = 'word2vec.6B.txt'\n",
    "\n",
    "glove_file = datapath(path_to_glove)\n",
    "tmp_file = get_tmpfile(tmp_file_name)\n",
    "\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the type the word vector of 'animal', the dimension (shape) of this vector, and the content of thie vector.\n",
    "\n",
    "If you use 300 dimensions word vectors, the correct outout will be something like this:\n",
    "```\n",
    "(numpy.ndarray,\n",
    " (300,),\n",
    " array([ 0.25653  ,  0.66592  , -0.5313   ,  0.20342  ,  0.40049  ,\n",
    " ... multiple lines are omitted ...\n",
    "        -0.14921  ,  0.2404   ,  0.22182  ,  0.68883  , -0.018991 ],\n",
    "       dtype=float32))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[ 0.49652   -0.65143   -1.0869    -0.10205    0.81724    0.923\n",
      " -0.56206   -1.3801     1.8115     0.068438   0.63906    0.24468\n",
      "  1.0308     0.10202    0.48498   -0.08387    0.61688    0.35812\n",
      " -0.75196   -0.3548    -0.14173    0.042311   0.42242   -0.21013\n",
      "  0.28935   -1.1214    -0.5278    -0.046298   0.064643  -0.43924\n",
      "  2.4004    -0.29715   -0.19765   -0.88725   -0.62955    0.64092\n",
      "  0.14741   -0.0089431  0.39569    0.060899  -0.33917   -0.15897\n",
      "  0.22115    0.83813    1.6032    -0.010252  -0.36843   -0.32005\n",
      "  0.4658    -0.10813  ]\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: please print the type the word vector of 'animal', the dimension    #\n",
    "# (shape) of this vector, and the content of thie vector.                   #\n",
    "#############################################################################\n",
    "print(type(model.get_vector('animal')))\n",
    "print(model.get_vector('animal'))\n",
    "print(model.get_vector('animal').shape)\n",
    "\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [similar_by_vector](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.similar_by_vector) to obtain the 10 most similar word to 'france'\n",
    "\n",
    "If you use 300 dimensions word vectors, the correct outout will be something like this:\n",
    "```\n",
    "[('france', 1.0),\n",
    " ('french', 0.7344760894775391),\n",
    " ('paris', 0.6580672264099121),\n",
    " ('belgium', 0.620672345161438),\n",
    " ('spain', 0.573593258857727),\n",
    " ('italy', 0.5643459558486938),\n",
    " ('germany', 0.5567397475242615),\n",
    " ('prohertrib', 0.5564222931861877),\n",
    " ('britain', 0.5553334951400757),\n",
    " ('chirac', 0.5362644195556641)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', 0.9999999403953552),\n",
       " ('french', 0.8868120908737183),\n",
       " ('belgium', 0.8631513118743896),\n",
       " ('paris', 0.8025329113006592),\n",
       " ('spain', 0.7909148931503296),\n",
       " ('netherlands', 0.7893801331520081),\n",
       " ('italy', 0.7788637280464172),\n",
       " ('germany', 0.7744609117507935),\n",
       " ('european', 0.7626757025718689),\n",
       " ('switzerland', 0.757765531539917)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: use similar_by_vector to obtain the 10 most similar word to 'france'#\n",
    "#############################################################################\n",
    "model.similar_by_vector(model.get_vector('france'))\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [most_similar](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.Word2VecKeyedVectors.most_similar) to obtain the result of 'woman' + 'king' - 'man'\n",
    "\n",
    "If you use 300 dimensions, the correct output will be somthing like this:\n",
    "```\n",
    "[('queen', 0.6713277101516724),\n",
    " ('princess', 0.5432624220848083),\n",
    " ('throne', 0.5386104583740234),\n",
    " ('monarch', 0.5347574949264526),\n",
    " ('daughter', 0.498025119304657),\n",
    " ('mother', 0.4956442713737488),\n",
    " ('elizabeth', 0.4832652509212494),\n",
    " ('kingdom', 0.47747087478637695),\n",
    " ('prince', 0.4668239951133728),\n",
    " ('wife', 0.4647327661514282)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523603677749634),\n",
       " ('throne', 0.7664334177970886),\n",
       " ('prince', 0.759214460849762),\n",
       " ('daughter', 0.7473883032798767),\n",
       " ('elizabeth', 0.7460220456123352),\n",
       " ('princess', 0.7424569725990295),\n",
       " ('kingdom', 0.7337411642074585),\n",
       " ('monarch', 0.7214490175247192),\n",
       " ('eldest', 0.7184861898422241),\n",
       " ('widow', 0.7099430561065674)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: use most_similar to obtain the result of 'woman' + 'king' - 'man'   #\n",
    "#############################################################################\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [doesnt_match](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.doesnt_match) to obtain the word with the different meaning with the other words in a list 'breakfast', 'lunch', 'dinner', 'cereal'\n",
    "\n",
    "If you use 300 dimensions, the correct output will be something like this:\n",
    "```\n",
    "'cereal'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: Use doesnt_match to obtain the word with the different meaning with #\n",
    "# the other words in a list 'breakfast', 'lunch', 'dinner', 'cereal'        #\n",
    "#############################################################################\n",
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pca_plot(model):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = PCA(n_components = 2)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    for i in range(len(x)):\n",
    "        label = labels[i]\n",
    "        if label in ['king', 'queen', 'sister', 'brother', 'niece', 'nephew', 'aunt', 'uncle', 'woman', 'man', \n",
    "                     'madam', 'sir']:\n",
    "            plt.scatter(x[i],y[i])\n",
    "            plt.annotate(label,\n",
    "                         xy = (x[i], y[i]),\n",
    "                         xytext = (5, 2),\n",
    "                         textcoords = 'offset points',\n",
    "                         ha = 'right',\n",
    "                         va = 'bottom')\n",
    "    plt.show()\n",
    "\n",
    "pca_plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuter-21578 Data set with word2vec\n",
    "Last week, you have already worked on Reuters-21578 dataset for multi-class classification. This week, you are using word2vec to classify the same dataset.\n",
    "\n",
    "In this lab, you will have to implement 3 three neural network models using keras API:\n",
    "1. Mutilayer perceptron\n",
    "2. Conv1D\n",
    "3. LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n"
     ]
    }
   ],
   "source": [
    "# this requires download from the first time\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = MAX_NB_WORDS, \n",
    "                                                         skip_top = 0, \n",
    "                                                         maxlen = MAX_SEQUENCE_LENGTH,\n",
    "                                                         seed = 113,\n",
    "                                                         start_char = 1, \n",
    "                                                         oov_char = 2, \n",
    "                                                         index_from = 3)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "word2index = reuters.get_word_index()\n",
    "word2index = {key : (value + 3) for (key, value) in word2index.items()}\n",
    "word2index['<PAD>'] = 0\n",
    "word2index['<START>'] = 1\n",
    "word2index['<UNK>'] = 2\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: create a embeddings_index to map word to word vector and print the  #\n",
    "# number of words in the embedding                                          #\n",
    "#############################################################################\n",
    "embeddings_index = dict()\n",
    "for (key, value) in word2index.items():\n",
    "    \n",
    "    try: \n",
    "        embeddings_index[key] = model.get_vector(key)\n",
    "    except: \n",
    "        embeddings_index[key] = np.zeros((EMBEDDING_DIM,))\n",
    "#         print('{} not in wordvectors'.format(key))\n",
    "\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# TODO: create a embedding_matrix that map the index of word2index to word  #\n",
    "# vectors                                                                   #\n",
    "#############################################################################\n",
    "embedding_matrix = np.zeros((MAX_NB_WORDS, EMBEDDING_DIM))\n",
    "\n",
    "for (key, value) in word2index.items():\n",
    "    if (value < MAX_NB_WORDS):\n",
    "        embedding_matrix[value] = embeddings_index[key]\n",
    "    else:\n",
    "        continue\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# TODO: define an embedding layer that initialize the weights with          #                                         \n",
    "# embedding_matrix and set trainable to False                               #\n",
    "#############################################################################\n",
    "pass\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################\n",
    "embedding_layer = Embedding(MAX_NB_WORDS,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SEQUENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Use keras pad_sequences to pad the sequence in X_train and X_test   #\n",
    "# to MAX_SEQUENCE_LENGTH                                                    #\n",
    "#############################################################################\n",
    "# print(X_train[0])\n",
    "# print(X_test[0])\n",
    "# X_train_shape = X_train.shape\n",
    "# X_test_shape = X_test.shape\n",
    "# print(X_train_shape)\n",
    "# print(X_test_shape)\n",
    "# X_train2 = np.zeros((len(X_train)))\n",
    "X_train = pad_sequences(X_train, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train tensor: (7976, 300)\n",
      "Shape of X_test tensor: (1994, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train tensor:', X_train.shape)\n",
    "print('Shape of X_test tensor:', X_test.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_train = X_train[indices]\n",
    "y_train = y_train[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * X_train.shape[0])\n",
    "\n",
    "X_val = X_train[-nb_validation_samples:]\n",
    "y_val = y_train[-nb_validation_samples:]\n",
    "X_train = X_train[:-nb_validation_samples]\n",
    "y_train = y_train[:-nb_validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + multiple layer perceptron\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 300)               0         \n",
    "_________________________________________________________________\n",
    "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 90000)             0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 128)               11520128  \n",
    "_________________________________________________________________\n",
    "activation_1 (Activation)    (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 64)                8256      \n",
    "_________________________________________________________________\n",
    "activation_2 (Activation)    (None, 64)                0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 32)                2080      \n",
    "_________________________________________________________________\n",
    "activation_3 (Activation)    (None, 32)                0         \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 46)                1518      \n",
    "_________________________________________________________________\n",
    "activation_4 (Activation)    (None, 46)                0         \n",
    "=================================================================\n",
    "Total params: 20,826,882\n",
    "Trainable params: 11,531,982\n",
    "Non-trainable params: 9,294,900\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 50)           500000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1920128   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46)                1518      \n",
      "=================================================================\n",
      "Total params: 2,431,982\n",
      "Trainable params: 1,931,982\n",
      "Non-trainable params: 500,000\n",
      "_________________________________________________________________\n",
      "Train on 5584 samples, validate on 2392 samples\n",
      "Epoch 1/20\n",
      "5584/5584 [==============================] - 3s 560us/step - loss: 2.8110 - acc: 0.4352 - val_loss: 2.0613 - val_acc: 0.5456\n",
      "Epoch 2/20\n",
      "5584/5584 [==============================] - 3s 465us/step - loss: 1.8510 - acc: 0.5611 - val_loss: 1.7449 - val_acc: 0.5874\n",
      "Epoch 3/20\n",
      "5584/5584 [==============================] - 2s 435us/step - loss: 1.5078 - acc: 0.6379 - val_loss: 1.5994 - val_acc: 0.6317\n",
      "Epoch 4/20\n",
      "5584/5584 [==============================] - 3s 580us/step - loss: 1.2345 - acc: 0.6995 - val_loss: 1.5163 - val_acc: 0.6426\n",
      "Epoch 5/20\n",
      "5584/5584 [==============================] - 3s 521us/step - loss: 0.9898 - acc: 0.7568 - val_loss: 1.4504 - val_acc: 0.6697\n",
      "Epoch 6/20\n",
      "5584/5584 [==============================] - 3s 563us/step - loss: 0.7779 - acc: 0.8148 - val_loss: 1.4182 - val_acc: 0.6839\n",
      "Epoch 7/20\n",
      "5584/5584 [==============================] - 3s 514us/step - loss: 0.6156 - acc: 0.8514 - val_loss: 1.4512 - val_acc: 0.6844\n",
      "Epoch 8/20\n",
      "5584/5584 [==============================] - 2s 444us/step - loss: 0.4767 - acc: 0.8841 - val_loss: 1.4520 - val_acc: 0.6919\n",
      "Epoch 9/20\n",
      "5584/5584 [==============================] - 2s 344us/step - loss: 0.3707 - acc: 0.9088 - val_loss: 1.4701 - val_acc: 0.6931\n",
      "Epoch 10/20\n",
      "5584/5584 [==============================] - 2s 343us/step - loss: 0.2831 - acc: 0.9327 - val_loss: 1.5536 - val_acc: 0.6865\n",
      "Epoch 11/20\n",
      "5584/5584 [==============================] - 2s 342us/step - loss: 0.2340 - acc: 0.9452 - val_loss: 1.6104 - val_acc: 0.6806\n",
      "Epoch 12/20\n",
      "5584/5584 [==============================] - 3s 569us/step - loss: 0.1875 - acc: 0.9574 - val_loss: 1.6917 - val_acc: 0.6827\n",
      "Epoch 13/20\n",
      "5584/5584 [==============================] - 3s 449us/step - loss: 0.1668 - acc: 0.9624 - val_loss: 1.6729 - val_acc: 0.6743\n",
      "Epoch 14/20\n",
      "5584/5584 [==============================] - 2s 411us/step - loss: 0.1482 - acc: 0.9654 - val_loss: 1.7443 - val_acc: 0.6785\n",
      "Epoch 15/20\n",
      "5584/5584 [==============================] - 2s 363us/step - loss: 0.1341 - acc: 0.9672 - val_loss: 1.7835 - val_acc: 0.6793\n",
      "Epoch 16/20\n",
      "5584/5584 [==============================] - 2s 345us/step - loss: 0.1233 - acc: 0.9696 - val_loss: 1.7950 - val_acc: 0.6869\n",
      "Epoch 17/20\n",
      "5584/5584 [==============================] - 2s 343us/step - loss: 0.1212 - acc: 0.9703 - val_loss: 1.8734 - val_acc: 0.6844\n",
      "Epoch 18/20\n",
      "5584/5584 [==============================] - 2s 412us/step - loss: 0.1137 - acc: 0.9688 - val_loss: 1.8971 - val_acc: 0.6881\n",
      "Epoch 19/20\n",
      "5584/5584 [==============================] - 2s 423us/step - loss: 0.1088 - acc: 0.9701 - val_loss: 1.8903 - val_acc: 0.6852\n",
      "Epoch 20/20\n",
      "5584/5584 [==============================] - 2s 430us/step - loss: 0.1034 - acc: 0.9685 - val_loss: 1.8507 - val_acc: 0.6827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe00c88e668>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: Define the model of multiple layer perceptron similar to the model  #\n",
    "# summary above into the variable model, compile it and fit it.             #\n",
    "#############################################################################\n",
    "#from keras.models import Sequential\n",
    "\n",
    "\n",
    "input_layer = Input(shape = (MAX_SEQUENCE_LENGTH, ))\n",
    "embedding = embedding_layer(input_layer)\n",
    "flatten = Flatten()(embedding)\n",
    "dense1 = Dense(128, activation = 'relu')(flatten)\n",
    "dense2 = Dense(64, activation = 'relu')(dense1)\n",
    "dense3 = Dense(32, activation = 'relu')(dense2)\n",
    "dense4 = Dense(46, activation = 'softmax')(dense3)\n",
    "\n",
    "model = Model(inputs = input_layer, outputs = dense4)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          epochs = 20, \n",
    "          batch_size = 512, \n",
    "          validation_data = (X_val, y_val))\n",
    "\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994/1994 [==============================] - 1s 559us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.094042325330713, 0.6619859578736209]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + Conv1D\n",
    "```\n",
    "_________________________________________________________________\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_2 (InputLayer)         (None, 300)               0         \n",
    "_________________________________________________________________\n",
    "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
    "_________________________________________________________________\n",
    "conv1d_1 (Conv1D)            (None, 296, 64)           96064     \n",
    "_________________________________________________________________\n",
    "max_pooling1d_1 (MaxPooling1 (None, 59, 64)            0         \n",
    "_________________________________________________________________\n",
    "flatten_2 (Flatten)          (None, 3776)              0         \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 3776)              0         \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 64)                241728    \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 64)                0         \n",
    "_________________________________________________________________\n",
    "dense_6 (Dense)              (None, 46)                2990      \n",
    "=================================================================\n",
    "Total params: 9,635,682\n",
    "Trainable params: 340,782\n",
    "Non-trainable params: 9,294,900\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 50)           500000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 297, 64)           12864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 59, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3776)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3776)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                241728    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 757,582\n",
      "Trainable params: 257,582\n",
      "Non-trainable params: 500,000\n",
      "_________________________________________________________________\n",
      "Train on 5584 samples, validate on 2392 samples\n",
      "Epoch 1/20\n",
      "5584/5584 [==============================] - 7s 1ms/step - loss: 2.8432 - acc: 0.3612 - val_loss: 2.0886 - val_acc: 0.5196\n",
      "Epoch 2/20\n",
      "5584/5584 [==============================] - 8s 1ms/step - loss: 2.1813 - acc: 0.4937 - val_loss: 1.8923 - val_acc: 0.5326\n",
      "Epoch 3/20\n",
      "5584/5584 [==============================] - 7s 1ms/step - loss: 1.9956 - acc: 0.5204 - val_loss: 1.7706 - val_acc: 0.5439\n",
      "Epoch 4/20\n",
      "5584/5584 [==============================] - 7s 1ms/step - loss: 1.8509 - acc: 0.5423 - val_loss: 1.6608 - val_acc: 0.5665\n",
      "Epoch 5/20\n",
      "5584/5584 [==============================] - 5s 981us/step - loss: 1.7330 - acc: 0.5698 - val_loss: 1.5598 - val_acc: 0.6054\n",
      "Epoch 6/20\n",
      "5584/5584 [==============================] - 7s 1ms/step - loss: 1.6152 - acc: 0.6110 - val_loss: 1.4813 - val_acc: 0.6304\n",
      "Epoch 7/20\n",
      "5584/5584 [==============================] - 6s 1ms/step - loss: 1.5542 - acc: 0.6241 - val_loss: 1.4275 - val_acc: 0.6572\n",
      "Epoch 8/20\n",
      "5584/5584 [==============================] - 6s 1000us/step - loss: 1.4775 - acc: 0.6474 - val_loss: 1.3782 - val_acc: 0.6685\n",
      "Epoch 9/20\n",
      "5584/5584 [==============================] - 5s 968us/step - loss: 1.4202 - acc: 0.6551 - val_loss: 1.3438 - val_acc: 0.6806\n",
      "Epoch 10/20\n",
      "5584/5584 [==============================] - 5s 971us/step - loss: 1.3714 - acc: 0.6639 - val_loss: 1.3007 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "5584/5584 [==============================] - 5s 972us/step - loss: 1.3254 - acc: 0.6785 - val_loss: 1.2805 - val_acc: 0.6952\n",
      "Epoch 12/20\n",
      "5584/5584 [==============================] - 6s 1ms/step - loss: 1.2794 - acc: 0.6918 - val_loss: 1.2446 - val_acc: 0.7099\n",
      "Epoch 13/20\n",
      "5584/5584 [==============================] - 5s 968us/step - loss: 1.2258 - acc: 0.6986 - val_loss: 1.2191 - val_acc: 0.7061\n",
      "Epoch 14/20\n",
      "5584/5584 [==============================] - 5s 974us/step - loss: 1.1739 - acc: 0.7090 - val_loss: 1.2024 - val_acc: 0.7140\n",
      "Epoch 15/20\n",
      "5584/5584 [==============================] - 5s 971us/step - loss: 1.1517 - acc: 0.7178 - val_loss: 1.1768 - val_acc: 0.7149\n",
      "Epoch 16/20\n",
      "5584/5584 [==============================] - 5s 976us/step - loss: 1.1204 - acc: 0.7215 - val_loss: 1.1668 - val_acc: 0.7174\n",
      "Epoch 17/20\n",
      "5584/5584 [==============================] - 5s 971us/step - loss: 1.0803 - acc: 0.7323 - val_loss: 1.1439 - val_acc: 0.7266\n",
      "Epoch 18/20\n",
      "5584/5584 [==============================] - 6s 1ms/step - loss: 1.0539 - acc: 0.7362 - val_loss: 1.1263 - val_acc: 0.7308\n",
      "Epoch 19/20\n",
      "5584/5584 [==============================] - 6s 1ms/step - loss: 1.0161 - acc: 0.7475 - val_loss: 1.1155 - val_acc: 0.7333\n",
      "Epoch 20/20\n",
      "5584/5584 [==============================] - 5s 972us/step - loss: 0.9798 - acc: 0.7568 - val_loss: 1.0999 - val_acc: 0.7366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfd8bc0908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "# TODO: Define the model of 1D convolution similar to the model summary     #\n",
    "# above into the variable model, compile it and fit it.                     #\n",
    "#############################################################################\n",
    "\n",
    "# input_layer = Input(shape = (MAX_SEQUENCE_LENGTH, ))\n",
    "# embedding = embedding_layer(input_layer)\n",
    "# flatten = Flatten()(embedding)\n",
    "# dense1 = Dense(128, activation = 'relu')(flatten)\n",
    "# dense2 = Dense(64, activation = 'relu')(dense1)\n",
    "# dense3 = Dense(32, activation = 'relu')(dense2)\n",
    "# dense4 = Dense(46, activation = 'softmax')(dense3)\n",
    "\n",
    "\n",
    "input_2 = Input(shape = (MAX_SEQUENCE_LENGTH,))\n",
    "embedding_1 = embedding_layer(input_2)\n",
    "conv1d_1 = Conv1D(64, 4, activation = 'relu')(embedding_1)\n",
    "max_pooling1d_1 = MaxPooling1D(5)(conv1d_1)\n",
    "flatten_2 = Flatten()(max_pooling1d_1)\n",
    "dropout_1 = Dropout(0.4)(flatten_2)\n",
    "dense_5 = Dense(64, activation = 'relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.3)(dense_5)\n",
    "dense_6 = Dense(46, activation = 'softmax')(dropout_2)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs = input_2, outputs = dense_6)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          epochs = 20, \n",
    "          batch_size = 512, \n",
    "          validation_data = (X_val, y_val))\n",
    "\n",
    "#############################################################################\n",
    "#                          END OF YOUR CODE                                 #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994/1994 [==============================] - 1s 545us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2134312522805921, 0.713640922887873]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + LSTM (GRU)\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_3 (InputLayer)         (None, 300)               0         \n",
    "_________________________________________________________________\n",
    "embedding_1 (Embedding)      (None, 300, 300)          9294900   \n",
    "_________________________________________________________________\n",
    "lstm_1 (LSTM)                (None, 128)               219648    \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 46)                5934      \n",
    "=================================================================\n",
    "Total params: 9,520,482\n",
    "Trainable params: 225,582\n",
    "Non-trainable params: 9,294,900\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 50)           500000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 597,582\n",
      "Trainable params: 97,582\n",
      "Non-trainable params: 500,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5584 samples, validate on 2392 samples\n",
      "Epoch 1/20\n",
      "5584/5584 [==============================] - 56s 10ms/step - loss: 3.1656 - acc: 0.3569 - val_loss: 2.3736 - val_acc: 0.3972\n",
      "Epoch 2/20\n",
      "5584/5584 [==============================] - 45s 8ms/step - loss: 2.3607 - acc: 0.3637 - val_loss: 2.2743 - val_acc: 0.3980\n",
      "Epoch 3/20\n",
      "5584/5584 [==============================] - 46s 8ms/step - loss: 2.3353 - acc: 0.3750 - val_loss: 2.2773 - val_acc: 0.3980\n",
      "Epoch 4/20\n",
      "5584/5584 [==============================] - 48s 9ms/step - loss: 2.3310 - acc: 0.3748 - val_loss: 2.2742 - val_acc: 0.3980\n",
      "Epoch 5/20\n",
      "5584/5584 [==============================] - 45s 8ms/step - loss: 2.3299 - acc: 0.3750 - val_loss: 2.2755 - val_acc: 0.3972\n",
      "Epoch 6/20\n",
      "5584/5584 [==============================] - 51s 9ms/step - loss: 2.3307 - acc: 0.3752 - val_loss: 2.2721 - val_acc: 0.3967\n",
      "Epoch 7/20\n",
      "5584/5584 [==============================] - 51s 9ms/step - loss: 2.3305 - acc: 0.3754 - val_loss: 2.2761 - val_acc: 0.3967\n",
      "Epoch 8/20\n",
      "5584/5584 [==============================] - 46s 8ms/step - loss: 2.3385 - acc: 0.3752 - val_loss: 2.2764 - val_acc: 0.3967\n",
      "Epoch 9/20\n",
      "5584/5584 [==============================] - 46s 8ms/step - loss: 2.3402 - acc: 0.3752 - val_loss: 2.2765 - val_acc: 0.3967\n",
      "Epoch 10/20\n",
      "5584/5584 [==============================] - 47s 8ms/step - loss: 2.3311 - acc: 0.3755 - val_loss: 2.2728 - val_acc: 0.3972\n",
      "Epoch 11/20\n",
      "5584/5584 [==============================] - 44s 8ms/step - loss: 2.3295 - acc: 0.3754 - val_loss: 2.2748 - val_acc: 0.3972\n",
      "Epoch 12/20\n",
      "5584/5584 [==============================] - 47s 8ms/step - loss: 2.3302 - acc: 0.3752 - val_loss: 2.2752 - val_acc: 0.3972\n",
      "Epoch 13/20\n",
      "5584/5584 [==============================] - 44s 8ms/step - loss: 2.3306 - acc: 0.3755 - val_loss: 2.2737 - val_acc: 0.3972\n",
      "Epoch 14/20\n",
      "5584/5584 [==============================] - 44s 8ms/step - loss: 2.3301 - acc: 0.3755 - val_loss: 2.2737 - val_acc: 0.3972\n",
      "Epoch 15/20\n",
      "5584/5584 [==============================] - 44s 8ms/step - loss: 2.3291 - acc: 0.3754 - val_loss: 2.2748 - val_acc: 0.3972\n",
      "Epoch 16/20\n",
      "5584/5584 [==============================] - 44s 8ms/step - loss: 2.3269 - acc: 0.3754 - val_loss: 2.2804 - val_acc: 0.3972\n",
      "Epoch 17/20\n",
      "5584/5584 [==============================] - 49s 9ms/step - loss: 2.3283 - acc: 0.3752 - val_loss: 2.2745 - val_acc: 0.3972\n",
      "Epoch 18/20\n",
      "5584/5584 [==============================] - 46s 8ms/step - loss: 2.3291 - acc: 0.3752 - val_loss: 2.2728 - val_acc: 0.3972\n",
      "Epoch 19/20\n",
      "5584/5584 [==============================] - 46s 8ms/step - loss: 2.3283 - acc: 0.3754 - val_loss: 2.2794 - val_acc: 0.3972\n",
      "Epoch 20/20\n",
      "5584/5584 [==============================] - 46s 8ms/step - loss: 2.3282 - acc: 0.3755 - val_loss: 2.2755 - val_acc: 0.3972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfd9688b38>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = 'int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "units = 128\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "layer1 = LSTM(units,\n",
    "    dropout = 0.2,\n",
    "    recurrent_dropout = 0.2,\n",
    "    return_sequences = False)\n",
    "x = layer1(embedded_sequences)\n",
    "\n",
    "final_layer = Dense(46, activation = 'softmax')\n",
    "preds = final_layer(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "print(model.summary())\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data = (X_val, y_val),\n",
    "          epochs = 20, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994/1994 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3135911043333555, 0.3971915748437405]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
